
defaults:
  - /pruning: sparse_trainer_args.yaml
  - override /trainer: default.yaml
  - override /model: pruner.yaml
  - override /datamodule: default.yaml
  - override /callbacks: default.yaml
  - override /logger: tensorboard.yaml

# Try: 32,64,128,256,384,768
prune_block_size: 32

# Eg: pruned/B32/bert-base-uncased/all-layer/token-pruning
exp_name: pruned/B${prune_block_size}/unfrozen/${model.model_name}/${model.embedding_layer}-layer/${model.mode}-pruning

pruning:
  attention_block_rows: ${prune_block_size}
  attention_block_cols: ${prune_block_size}

model:
  _target_: src.models.pruninig_model.PruningModel
  sparse_train_args: ${pruning}
  freeze_weights: False 
  share_pruning_scores: False
  prune_values_only: True
  prune_attention_only: True


datamodule:
  batch_size: 128
  num_workers: 0

callbacks:
  checkpoint_callback:
    compile_pruned: True

trainer:
  max_epochs: 100
